{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW6 programming problem 14 ~ 20\n",
    "\n",
    "This document aims to implement decision tree(CA&R tree) and random forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"hw6_train.dat.txt\", sep=\" \", header=None)\n",
    "test = pd.read_csv(\"hw6_test.dat.txt\", sep=\" \", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gini_index definition\n",
    "\n",
    "def impurity(y):\n",
    "    mu_pos = np.count_nonzero(y == 1) / len(y)\n",
    "    return 1 - mu_pos ** 2 - (1 - mu_pos) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminal Criterion\n",
    "def terminal(X: np.array, y: np.array) -> int:\n",
    "\n",
    "    # If all the y is the same\n",
    "    if len(np.unique(y)) == 1:\n",
    "        return True\n",
    "\n",
    "    # If all the x is the same\n",
    "    elif len(np.unique(X, axis=0)) == 1:\n",
    "        print(\"All Xn are the same\")\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Branch condition, output decision stump, chosing a cutting point theta and \n",
    "# using this cut to deduce impurity as quick as possible\n",
    "\n",
    "def branch_learning(X, y):\n",
    "    # Combine X and y to df\n",
    "    df = np.insert(X, X.shape[1], y, axis=1)\n",
    "    bEin, btheta, feature = 99999, 0, 0\n",
    "    leftX, rightX, lefty, righty = None, None, None, None\n",
    "\n",
    "    # For every column\n",
    "    for i in range(X.shape[1]):\n",
    "        # The whole df sort by ith column\n",
    "        ith_df = df[df[:, i].argsort()]\n",
    "        x_ith = ith_df[:, i]\n",
    "        # Create thetas as a list with n - 1 length\n",
    "        theta = [(a + b) / 2 for a, b in zip(x_ith[:-1], x_ith[1:])]\n",
    "\n",
    "        # For every theta\n",
    "        for j in range(1, len(y)):\n",
    "            # Divide dataset to twopart\n",
    "            y1, y2 = ith_df[:j, -1], ith_df[j:, -1]\n",
    "            \n",
    "            # Calculate the score\n",
    "            Ein = len(y1) * impurity(y1) + len(y2) * impurity(y2)\n",
    "            \n",
    "            # Find the smallest, and record the relative theta, feature, two groups of data\n",
    "            if Ein < bEin:\n",
    "                bEin = Ein\n",
    "                btheta = theta[j - 1]\n",
    "                feature = i\n",
    "                leftX, rightX, lefty, righty = ith_df[:j,\n",
    "                                                      :-1], ith_df[j:, :-1], y1, y2\n",
    "\n",
    "    return feature, btheta, leftX, rightX, lefty, righty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Tree(root, subtree)\n",
    "class node():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.feature = None # record branch criteria\n",
    "        self.threshhold = None # record branch criteria\n",
    "        self.left = None # record the left subtree address\n",
    "        self.right = None # record the right subtree address\n",
    "        self.value = None # If this node is a leaf, value record the base hypothesis\n",
    "\n",
    "    # Define training process\n",
    "    def train(self, X: np.array, y: np.array):\n",
    "        # If terminal criterion met, return the most frequent y\n",
    "        if terminal(X, y):\n",
    "            self.value = mode(y)[0][0]\n",
    "            \n",
    "        # If not\n",
    "        else:\n",
    "            # learn the branch criterion\n",
    "            self.feature, self.threshhold, X1, X2, y1, y2 = branch_learning(\n",
    "                X, y)\n",
    "            \n",
    "            # let left child and right child train new datasets\n",
    "            self.left, self.right = node(), node()\n",
    "            self.left.train(X1, y1)\n",
    "            self.right.train(X2, y2)\n",
    "\n",
    "    # Define predict process\n",
    "    def predict(self, X: np.array) -> int:\n",
    "        # If this node is leaf, return the base algorithm\n",
    "        if self.value != None:\n",
    "            return self.value\n",
    "        \n",
    "        # If this node is not leaf, choose whether go left or right\n",
    "        else:\n",
    "            if X[self.feature] < self.threshhold:\n",
    "                return self.left.predict(X)\n",
    "            else:\n",
    "                return self.right.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 14: \n",
      "Training cost 1.03\n",
      "Testing cost 0.01 sec\n",
      "In pb14, Eout is 0.17 sec\n"
     ]
    }
   ],
   "source": [
    "def problem14(train, test):\n",
    "    print(\"Problem 14: \")\n",
    "    \n",
    "    # Separate each X, y dataset\n",
    "    trainX, trainy = train.iloc[:, :-1], train.iloc[:, -1]\n",
    "    testX, testy = test.iloc[:, :-1], test.iloc[:, -1]\n",
    "\n",
    "    # Train DecisionTree\n",
    "    DecisionTree = node()\n",
    "    before = time.time()\n",
    "\n",
    "    DecisionTree.train(np.array(trainX),\n",
    "                       np.array(trainy))\n",
    "\n",
    "    after = time.time()\n",
    "    print(f\"Training cost {after - before:.2f}\")\n",
    "\n",
    "    before = time.time()\n",
    "\n",
    "    # Predict DecisionTree\n",
    "    y_pred = [DecisionTree.predict(x) for x in np.array(testX)]\n",
    "\n",
    "    after = time.time()\n",
    "    print(f\"Testing cost {after - before:.2f} sec\")\n",
    "    \n",
    "    # Calc. Eout\n",
    "    Eout = sum([y != y_hat for y, y_hat in zip(y_pred, testy)]) / len(y_pred)\n",
    "    print(f\"In pb14, Eout is {Eout:.2f}\")\n",
    "\n",
    "    return\n",
    "\n",
    "problem14(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 15: \n",
      "Total cost 710.83 sec\n",
      "In pb15, average Eout is 0.23\n"
     ]
    }
   ],
   "source": [
    "def problem15(train, test, n):\n",
    "    print(\"Problem 15: \")\n",
    "    \n",
    "    # Prepare n length Eoutlist and Forest\n",
    "    Eoutlist = []\n",
    "    Forest = []\n",
    "\n",
    "    before = time.time()\n",
    "    for _ in range(n):\n",
    "        # Bagging while N' = 0.5 N\n",
    "        train_15, test_15 = train.sample(\n",
    "            int(len(train) / 2), replace=True), test\n",
    "\n",
    "        # Separate datasets\n",
    "        trainX, trainy = train_15.iloc[:, :-1], train_15.iloc[:, -1]\n",
    "        testX, testy = test_15.iloc[:, :-1], test_15.iloc[:, -1]\n",
    "\n",
    "        # Train DecisionTree\n",
    "        DecisionTree = node()\n",
    "\n",
    "        DecisionTree.train(np.array(trainX),\n",
    "                           np.array(trainy))\n",
    "        \n",
    "        # Add it to the forest\n",
    "        Forest.append(DecisionTree)\n",
    "\n",
    "        # Predict y\n",
    "        y_pred = [DecisionTree.predict(x) for x in np.array(testX)]\n",
    "\n",
    "        # Calc. Eout\n",
    "        Eout = sum([y != y_hat for y, y_hat in zip(\n",
    "            y_pred, testy)]) / len(y_pred)\n",
    "        Eoutlist.append(Eout)\n",
    "\n",
    "    after = time.time()\n",
    "    print(f\"Total cost {after - before:.2f} sec\")\n",
    "\n",
    "    avgEout = sum(Eoutlist) / n\n",
    "\n",
    "    print(f\"In pb15, average Eout is {avgEout:.2f}\")\n",
    "\n",
    "    return Forest\n",
    "\n",
    "Forest = problem15(train, test, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 16: \n",
      "Total cost 8.06 sec\n",
      "In pb16, Ein is 0.01\n"
     ]
    }
   ],
   "source": [
    "def problem16(train, Forest):\n",
    "    print(\"Problem 16: \")\n",
    "    # G is the blending function\n",
    "    G = []\n",
    "    before = time.time()\n",
    "    \n",
    "    # Separate dataset\n",
    "    trainX, trainy = train.iloc[:, :-1], train.iloc[:, -1]\n",
    "    for tree in Forest:\n",
    "        y_pred = [tree.predict(x) for x in np.array(trainX)]\n",
    "        G.append(y_pred)\n",
    "\n",
    "    # If sign(g_1 + g_2 ... g_n) == 1: then G predict 1\n",
    "    G = np.array(G)\n",
    "    y_pred_G = [1 if i == 1 else -\n",
    "                1 for i in np.apply_along_axis(sum, 0, G) > 0]\n",
    "    \n",
    "    # Calc. Ein\n",
    "    Ein = sum([y != y_hat for y, y_hat in zip(\n",
    "        y_pred_G, trainy)]) / len(y_pred_G)\n",
    "\n",
    "    after = time.time()\n",
    "    print(f\"Total cost {after - before:.2f} sec\")\n",
    "    print(f\"In pb16, Ein is {Ein:.2f}\")\n",
    "    \n",
    "problem16(train, Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 17: \n",
      "In pb17, Eout is 0.15\n"
     ]
    }
   ],
   "source": [
    "def problem17(test, Forest):\n",
    "    print(\"Problem 17: \")\n",
    "    # G is the blending function\n",
    "    G = []\n",
    "    testX, testy = test.iloc[:, :-1], test.iloc[:, -1]\n",
    "    \n",
    "    # Using every tree to predict each x and return an N * 2000 matrix\n",
    "    for tree in Forest:\n",
    "        y_pred = [tree.predict(x) for x in np.array(testX)]\n",
    "        G.append(y_pred)\n",
    "\n",
    "    # Aggregate along column axis, if sum > 0, then return 1 else -1\n",
    "    G = np.array(G)\n",
    "    y_pred_G = [1 if i == 1 else -\n",
    "                1 for i in np.apply_along_axis(sum, 0, G) > 0]\n",
    "    \n",
    "    # Calc. Eout\n",
    "    Eout = sum([y != y_hat for y, y_hat in zip(\n",
    "        y_pred_G, testy)]) / len(y_pred_G)\n",
    "\n",
    "    print(f\"In pb17, Eout is {Eout:.2f}\")\n",
    "    \n",
    "problem17(test, Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 18: \n",
      "Eval is 0.07\n"
     ]
    }
   ],
   "source": [
    "def problem18(train, n):\n",
    "    print(\"Problem 18: \")\n",
    "    # Forest will save all trees, index_dict record: index_dict[train.index] = set(Which tree has used it)\n",
    "    Forest = []\n",
    "    index_dict = {}\n",
    "    \n",
    "    # Validation error\n",
    "    Eval = 0\n",
    "    \n",
    "    # Initialize index_dict as empty set for all n\n",
    "    for i in range(len(train)):\n",
    "        index_dict[i] = set()\n",
    "    \n",
    "    # Run n times\n",
    "    for i in range(n):\n",
    "        # Separate dataset\n",
    "        train_18 = train.sample(int(len(train) / 2), replace=True)\n",
    "        trainX, trainy = train_18.iloc[:, :-1], train_18.iloc[:, -1]\n",
    "        \n",
    "        \n",
    "        # Record whether xn has been used for tree i\n",
    "        used_index = set(train_18.index)\n",
    "        for chosen in used_index:\n",
    "            index_dict[chosen].add(i)\n",
    "        \n",
    "        # Train DecisionTree\n",
    "        DecisionTree = node()\n",
    "\n",
    "        DecisionTree.train(np.array(trainX),\n",
    "                           np.array(trainy))\n",
    "\n",
    "        # Add it to the Forest\n",
    "        Forest.append(DecisionTree)\n",
    "        \n",
    "    # CompleteSet: A set from 0 to n integers\n",
    "    completeSet = set([i for i in range(n)])\n",
    "    \n",
    "    # for every xn\n",
    "    for i in range(len(train)):\n",
    "        # For xn, find trees don't pick it, is the complement of index_dict[n]\n",
    "        G_minus = completeSet.difference(index_dict[i])\n",
    "        y_pred = 0\n",
    "        \n",
    "        # If xn has been used in every tree, return constant hypothesis -1\n",
    "        if len(G_minus) == 0:\n",
    "            y_pred = -1\n",
    "        \n",
    "        # else, create G- predict G-(xn)\n",
    "        else:\n",
    "            y_pred_list = []\n",
    "            for j in G_minus:\n",
    "                y_pred_list.append(Forest[j].predict(np.array(train.iloc[i, :-1])))\n",
    "\n",
    "            y_pred = 1 if sum(y_pred_list) > 0 else -1\n",
    "            \n",
    "        # Calc. Eval\n",
    "        if y_pred != train.iloc[:, -1][i]:\n",
    "            Eval += 1\n",
    "    \n",
    "    Eval /= len(train)\n",
    "    print(f\"Eval is {Eval:.2f}\")\n",
    "    \n",
    "problem18(train, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 19: (d) aggregation models: AdaBoost and Gradient Boosting\n",
    "\n",
    "老師在上課講的例子很生動，演算法邏輯也符合人性，況且實用性又高，透過alpha和un 的相對關係，又可以知道機器在哪個地方學得不好。\n",
    "\n",
    "我認為我在這個演算法上收益良多，是老師講解得足夠清楚的功勞\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 20: (b) matrix factorization\n",
    "\n",
    "我認為他很靠近neuron network，事實上好像也是這樣，況且即使了解他的規則，要如何加入新xn和ym (新成員和新電影)，以及中間的neuron該放幾個，怎麼validation，都不是很明朗\n",
    "\n",
    "感覺是最不清楚的一個部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end of document\n"
     ]
    }
   ],
   "source": [
    "print(\"end of document\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
